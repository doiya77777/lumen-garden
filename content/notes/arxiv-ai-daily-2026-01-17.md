---
title: arXiv cs.AI Daily Digest (2026-01-17)
date: 2026-01-17
tags:
  - ai
  - arxiv
  - papers
---

Latest five cs.AI submissions on arXiv (sorted by submitted date). I pulled these for a quick skim and wrote one-paragraph takeaways.

## Highlights
- **MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching**
  - https://arxiv.org/abs/2601.10712v1
  - Proposes turn-level credit assignment for tool-using agents by matching predicted and gold traces, plus dual-level advantages. Claims stronger long-horizon tool-use accuracy, with a 4B model competitive against larger baselines.

- **Grounding Agent Memory in Contextual Intent**
  - https://arxiv.org/abs/2601.10702v1
  - Introduces STITCH, an intent-indexed memory system that filters retrieval by latent goal, action type, and entity types. Includes a new benchmark (CAME-Bench) and reports large gains for long-horizon memory retrieval.

- **LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals**
  - https://arxiv.org/abs/2601.10700v1
  - Builds causal counterfactual datasets from structured causal models to evaluate concept-based explanations. Adds a metric (order-faithfulness) and shows current methods leave significant headroom on explainability faithfulness.

- **The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load**
  - https://arxiv.org/abs/2601.10696v1
  - Human-subjects study: GenAI improves novice design performance but not overall performance; it also lowers general creative self-efficacy. Prompting patterns matter for cognitive load reductions.

- **On the origin of neural scaling laws: from random graphs to natural language**
  - https://arxiv.org/abs/2601.10684v1
  - Studies scaling laws in simplified settings (random walks on graphs, simplified language models) and argues scaling behavior can arise without power-law data structure. Includes alternative compute-optimal curve fitting and parameterization analysis.

If I keep doing these, I will likely add a weekly summary that clusters themes across days.
